# DrupalGym Pipeline Configuration
project_name: "DrupalGym"
version: "1.0.0"
seed: 42

directories:
  raw: "raw"
  clean: "clean"
  sft: "sft"
  quality: "quality"
  dataset: "dataset"
  eval: "eval"
  models: "models"
  manifests: "manifests"
  sources: "sources"

sources:
  drupal_core:
    type: "git"
    url: "https://git.drupalcode.org/project/drupal.git"
    branch: "11.x"
  drupal_projects:
    type: "api"
    endpoint: "https://www.drupal.org/api-d7/node.json"
    filters:
      core_compatibility: "^11"
    user_agent: "DrupalGym/1.0"
    max_pages: 10
    limit: 1000
    sort: "changed"
    direction: "desc"
  discovery:
    max_pages: 20
    limit_per_page: 50
    min_last_changed_days: 365
    max_projects_after_filter: 200
  filters:
    require_drupal_core_constraint: "^11"
    require_php_constraint_min: "8.3"
    exclude_archived_or_security_only: true

acquisition:
  docs:
    max_pages_per_source: 300
    allowed_prefixes:
      drupal_docs:
        - "https://www.drupal.org/docs/develop"
      drupal_api:
        - "https://api.drupal.org/api/drupal"
      symfony_docs:
        - "https://symfony.com/doc/7.0/"
      drupal_security:
        - "https://www.drupal.org/security"

normalization:
  dedup:
    exact_hash: true
    near_dup_enabled: true
    near_dup_method: "simhash_5gram"
    near_dup_threshold: 0.92

sft_generation:
  enable_symbol_kind_prompts: true
  include_extensions: [".php", ".module", ".inc", ".install", ".theme", ".yml", ".twig", ".md"]

quality:
  run_php_lint: true
  min_output_chars: 220
  max_output_chars: 30000

dataset:
  training_version: "v2"
  targets:
    train: 0.8
    valid: 0.1
    test: 0.1
  max_seq_len: 1024

dataset_refinement:
  input_version: "v1"
  output_version: "v2"
  seed: 42
  max_output_lines: 300
  chunk_overlap_lines: 30
  target_test_ratio: 0.15
  exclude_test_sources_from_training_pool: true
  augmentation:
    enabled: true
    ratio: 0.75
    input_excerpt_lines: 120
    types:
      - "bugfix"
      - "refactor"
      - "write_from_spec"
      - "explain_and_implement"

training:
  test_run:
    max_seq_len: 2048
    max_steps: 100
    per_device_train_batch_size: 1
    per_device_eval_batch_size: 1
    gradient_accumulation_steps: 16
    learning_rate: 0.0002
    logging_steps: 5
    eval_strategy: "no"
    save_strategy: "no"
    fp16: false
    bf16: false
    gradient_checkpointing: true
    use_reentrant_gc: false
    group_by_length: false
    lora_r: 32
    lora_alpha: 64
    lora_dropout: 0.05
    lora_target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    bnb_4bit_compute_dtype: "float32"
    max_models: 1
    models:
      - name: "Qwen2.5-Coder-3B-Test"
        base_model: "Qwen/Qwen2.5-Coder-3B"
        training_type: "QLoRA"
  full_scale:
    max_seq_len: 2048
    num_train_epochs: 3
    max_steps: 70
    per_device_train_batch_size: 1
    per_device_eval_batch_size: 1
    gradient_accumulation_steps: 32 # L40S-safe effective batch for current dataset volume
    learning_rate: 0.0002
    logging_steps: 1
    eval_strategy: "steps"
    eval_steps: 20
    save_strategy: "steps"
    save_steps: 20
    fp16: false
    bf16: true
    gradient_checkpointing: true
    use_reentrant_gc: false
    group_by_length: true
    lora_r: 64
    lora_alpha: 128
    lora_dropout: 0.05
    lora_target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    bnb_4bit_compute_dtype: "bfloat16"
    max_models: 1 # Focus on one model for the L40S full_scale session
    models:
      - name: "Qwen2.5-Coder-7B"
        base_model: "Qwen/Qwen2.5-Coder-7B"
        training_type: "QLoRA"

evaluation:
  seed: 42
  mode: "test_run"
  max_new_tokens: 512
  device: "auto"
  max_models: 1
  run_php_lint: true
  run_phpcs: false
  max_code_checks_per_response: 3

export:
  formats: ["safetensors", "gguf"]
  quantization:
    gguf: ["Q4_K_M", "Q8_0"]
  merge_adapters: true
  tools:
    llama_cpp_dir:
    convert_hf_to_gguf:
    llama_quantize:

models:
  - name: "Qwen2.5-Coder-7B"
    base_model: "Qwen/Qwen2.5-Coder-7B"
    training_type: "QLoRA"
  - name: "Ministral-3-8B"
    base_model: "mistralai/Ministral-3-8B-Instruct-2410"
    training_type: "QLoRA"
